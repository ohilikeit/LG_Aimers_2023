{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rnvc6vIPwyjm",
        "9NWbT0ZujlP8",
        "yHnaCEjCjxD_",
        "1A_5bF8soNF9",
        "Os-HbRdq7gv9"
      ],
      "machine_shape": "hm",
      "mount_file_id": "1tumAFqTiXkwPiW_UXXFDm49UtAEKUEqf",
      "authorship_tag": "ABX9TyNH67mXvGa60BNKozC/wvH6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ohilikeit/LG_Aimers_2023/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna\n",
        "! pip install catboost"
      ],
      "metadata": {
        "id": "XDJ9aluJhK3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oVJwOob_UgF2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "4ab2fe9c-99e2-42ec-d4f7-46659bdf0134"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         LINE  PRODUCT_CODE   X_1       X_2  X_4  X_5   X_7  X_8       X_9  \\\n",
              "0   -0.666667          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "1   -0.333333          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "2   -0.666667          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "3   -0.333333          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "4   -0.666667          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "..        ...           ...   ...       ...  ...  ...   ...  ...       ...   \n",
              "593  0.333333           0.0   0.0  0.042105  0.0  0.0  0.10  0.0  0.403846   \n",
              "594 -0.666667          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "595 -0.666667          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "596  0.000000          -0.5  19.0  0.031579  0.0  0.1  0.00  0.0  0.000000   \n",
              "597  0.333333          -0.5   9.5 -0.042105  0.0  0.0  0.32  0.0  0.403846   \n",
              "\n",
              "     X_10  ...    X_2864    X_2865  X_2866  X_2867  X_2868  X_2869  X_2870  \\\n",
              "0    -1.0  ...  0.997188  1.000000   39.34   40.89   32.56   34.09   77.77   \n",
              "1    -1.0  ...  0.995670  1.000000   38.89   42.82   43.92   35.34   72.55   \n",
              "2    -1.0  ...  0.994547  1.000000   39.19   36.65   42.47   36.53   78.35   \n",
              "3    -1.0  ...  0.999604  1.000000   37.74   39.17   52.17   30.58   71.78   \n",
              "4    -1.0  ...  0.994631  0.997167   38.70   41.89   46.93   33.09   76.97   \n",
              "..    ...  ...       ...       ...     ...     ...     ...     ...     ...   \n",
              "593   0.0  ...  0.000000  0.000000    0.00    0.00    0.00    0.00    0.00   \n",
              "594  -1.0  ...  1.001290  1.000000   49.47   53.07   50.89   55.10   66.49   \n",
              "595  -1.0  ...  0.993729  0.997167    0.00    0.00    0.00    0.00    0.00   \n",
              "596   0.0  ...  0.000000  0.000000    0.00    0.00    0.00    0.00    0.00   \n",
              "597   0.0  ...  0.000000  0.000000    0.00    0.00    0.00    0.00    0.00   \n",
              "\n",
              "     X_2871  Y_Class  Y_Quality  \n",
              "0       0.0        1   0.533433  \n",
              "1       0.0        2   0.541819  \n",
              "2       0.0        1   0.531267  \n",
              "3       0.0        2   0.537325  \n",
              "4       0.0        1   0.531590  \n",
              "..      ...      ...        ...  \n",
              "593     0.0        1   0.526546  \n",
              "594     1.0        0   0.524022  \n",
              "595     1.0        0   0.521289  \n",
              "596     0.0        1   0.531375  \n",
              "597     0.0        1   0.533702  \n",
              "\n",
              "[598 rows x 2598 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54c7990f-f942-4d92-a4ce-f34c596aa444\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LINE</th>\n",
              "      <th>PRODUCT_CODE</th>\n",
              "      <th>X_1</th>\n",
              "      <th>X_2</th>\n",
              "      <th>X_4</th>\n",
              "      <th>X_5</th>\n",
              "      <th>X_7</th>\n",
              "      <th>X_8</th>\n",
              "      <th>X_9</th>\n",
              "      <th>X_10</th>\n",
              "      <th>...</th>\n",
              "      <th>X_2864</th>\n",
              "      <th>X_2865</th>\n",
              "      <th>X_2866</th>\n",
              "      <th>X_2867</th>\n",
              "      <th>X_2868</th>\n",
              "      <th>X_2869</th>\n",
              "      <th>X_2870</th>\n",
              "      <th>X_2871</th>\n",
              "      <th>Y_Class</th>\n",
              "      <th>Y_Quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.997188</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>39.34</td>\n",
              "      <td>40.89</td>\n",
              "      <td>32.56</td>\n",
              "      <td>34.09</td>\n",
              "      <td>77.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.533433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.995670</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>38.89</td>\n",
              "      <td>42.82</td>\n",
              "      <td>43.92</td>\n",
              "      <td>35.34</td>\n",
              "      <td>72.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.541819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.994547</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>39.19</td>\n",
              "      <td>36.65</td>\n",
              "      <td>42.47</td>\n",
              "      <td>36.53</td>\n",
              "      <td>78.35</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.531267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999604</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>37.74</td>\n",
              "      <td>39.17</td>\n",
              "      <td>52.17</td>\n",
              "      <td>30.58</td>\n",
              "      <td>71.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.537325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.994631</td>\n",
              "      <td>0.997167</td>\n",
              "      <td>38.70</td>\n",
              "      <td>41.89</td>\n",
              "      <td>46.93</td>\n",
              "      <td>33.09</td>\n",
              "      <td>76.97</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.531590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>593</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042105</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.403846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.526546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.001290</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>49.47</td>\n",
              "      <td>53.07</td>\n",
              "      <td>50.89</td>\n",
              "      <td>55.10</td>\n",
              "      <td>66.49</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.524022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.993729</td>\n",
              "      <td>0.997167</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.521289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.031579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.531375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-0.042105</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.403846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.533702</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>598 rows × 2598 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54c7990f-f942-4d92-a4ce-f34c596aa444')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54c7990f-f942-4d92-a4ce-f34c596aa444 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54c7990f-f942-4d92-a4ce-f34c596aa444');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import f1_score, mean_squared_error\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import ExtraTreesRegressor, ExtraTreesClassifier\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from lightgbm import LGBMRegressor, LGBMClassifier\n",
        "\n",
        "from catboost import CatBoostRegressor\n",
        "import optuna\n",
        "from optuna import Trial, visualization\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "seed_everything(42)\n",
        "os.chdir('/content/drive/MyDrive/ML_projects/LG_Aimers')\n",
        "train = pd.read_csv('./train.csv').fillna(0)\n",
        "test = pd.read_csv('./test.csv').fillna(0)\n",
        "sample_submission = pd.read_csv('./sample_submission.csv')\n",
        "\n",
        "qual_col = ['LINE', 'PRODUCT_CODE']\n",
        "\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train[i])\n",
        "    train[i] = le.transform(train[i])\n",
        "    \n",
        "    for label in np.unique(test[i]): \n",
        "        if label not in le.classes_: \n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test[i] = le.transform(test[i])\n",
        "\n",
        "# 값이 하나만 있는거 삭제(0으로 이미 채웠는데도 1개이면 모든 행이 동일한 값을 갖고있다는 뜻)\n",
        "for i in train.columns:\n",
        "    if len(train[i].value_counts().keys()) == 1:\n",
        "        train.drop(i, axis=1, inplace=True)\n",
        "        test.drop(i, axis=1, inplace=True)\n",
        "\n",
        "X = train.drop(['PRODUCT_ID', 'Y_Class', 'Y_Quality', 'TIMESTAMP'], axis=1)\n",
        "y = train[['Y_Class', 'Y_Quality']]\n",
        "test = test.drop(['PRODUCT_ID', 'TIMESTAMP'], axis=1)\n",
        "\n",
        "# scaling\n",
        "scaler = RobustScaler()\n",
        "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
        "test = pd.DataFrame(scaler.transform(test), columns = test.columns)\n",
        "test.drop(['LINE', 'PRODUCT_CODE'], axis=1, inplace=True)\n",
        "\n",
        "train = pd.concat([X, y], axis=1)\n",
        "train\n",
        "# train.groupby(['LINE', 'PRODUCT_CODE'])['Y_Class'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff_df = train.groupby('Y_Class')['Y_Quality'].describe().reset_index()\n",
        "cut_1 = (cutoff_df.loc[0, 'max'] + cutoff_df.loc[1, 'min']) / 2\n",
        "cut_2 = (cutoff_df.loc[1, 'max'] + cutoff_df.loc[2, 'min']) / 2\n",
        "\n",
        "train.drop('Y_Class', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "RJaecoHYsBDB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 7)\n",
        "\n",
        "# 학습함수 정의 \n",
        "def objective(trial: Trial, train):\n",
        "    param = {\n",
        "        'verbose' : 0,\n",
        "        'random_state': 7,\n",
        "        'n_iter_no_change' : 50,\n",
        "        'validation_fraction' : 0.1,\n",
        "        'learning_rate' : 0.1,\n",
        "        'n_estimators' : trial.suggest_int('n_estimators', 100, 2000, step=20),\n",
        "        'min_impurity_decrease' : trial.suggest_float('min_impurity_decrease', 0, 0.2),\n",
        "        'max_depth' : trial.suggest_int('max_depth', 2, 20),\n",
        "        'max_features' : trial.suggest_categorical('max_features', ['auto', 'log2']),\n",
        "        'subsample' : trial.suggest_float('subsample', 0.7, 1.0, step=0.1)\n",
        "    }\n",
        "    cv_accuracy = []\n",
        "    cv = KFold(n_splits = 5)\n",
        "    n_iter = 0\n",
        "\n",
        "    for t,v in cv.split(train, train['Y_Quality']):\n",
        "        train_cv = train.iloc[t]\n",
        "        val_cv = train.iloc[v]\n",
        "\n",
        "        X = train_cv.drop('Y_Quality', axis=1)\n",
        "        y = train_cv['Y_Quality']\n",
        "\n",
        "        val_X = val_cv.drop('Y_Quality', axis=1)\n",
        "        val_y = val_cv['Y_Quality']\n",
        "\n",
        "        model = GradientBoostingRegressor(**param)\n",
        "\n",
        "        model.fit(X, y)\n",
        "        score = mean_squared_error(val_y, model.predict(val_X), squared = False)\n",
        "\n",
        "        cv_accuracy.append(score)\n",
        "        n_iter += 1\n",
        "\n",
        "    return np.mean(cv_accuracy)\n",
        "\n",
        "# create study\n",
        "GB_study = optuna.create_study(\n",
        "    direction='minimize',\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    pruner=optuna.pruners.HyperbandPruner(),\n",
        "    study_name='GB-Hyperparameter-Tuning'\n",
        ")\n",
        "\n",
        "# 학습 \n",
        "GB_study.optimize(lambda trial: objective(trial,train), \n",
        "               n_trials=50)\n",
        "print('Best trial : score {}, \\nparams {}'.format(GB_study.best_trial.value, GB_study.best_trial.params))"
      ],
      "metadata": {
        "id": "su1LvETHwzyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GB_model = GradientBoostingClassifier(**GB_study.best_trial.params, random_state = 42, n_iter_no_change = 50, validation_fraction = 0.1, learning_rate = 0.05)\n",
        "GB_model.fit(X, y)\n",
        "GB_pred = GB_model.predict(test)\n",
        "print(pd.DataFrame(GB_pred).value_counts())\n",
        "\n",
        "sample_submission['Y_Class'] = GB_pred\n",
        "sample_submission.to_csv('./submit.csv', index=False)"
      ],
      "metadata": {
        "id": "FTubg5vDw3Kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVC(kernel = 'poly)로 stacking이나 활용하자 / split은 0.2 기준 0 나왔음. \n",
        "# 할때 범주형 변수 labelencoding 해놨으니 얘네는 빼고 돌려보고 더 좋은 걸로 하자 \n",
        "\n",
        "# y_class 나뉘는걸 보면 굉장히 민감하게 나뉘는거같은데 pca와 같은 차원축소 기법이 과연 옳을 것인가는 의문\n",
        "# 이건 해보고 성능 높아지면 쓰고 아니면 안쓰기 \n",
        "\n",
        "# 공정 데이터이고 각 컬럼이 비식별화되어 함부로 판단하기 힘듦. \n",
        "# 결측치로 비어있는 부분은 아마 line이나 product code가 다름에 따라 해당 공정이 없는 경우일 것으로 예상됨.\n",
        "# 이상치 처리는 건들지 말고 결측치는 0으로 두어 모델에 반영되지 않게 하자. \n",
        "\n",
        "# line, product 4-1 이랑 5-1 조합 train에선 3 3 이고 test에선 3 1 인데 이거 빼고 아니고 성능 차이 확인 "
      ],
      "metadata": {
        "id": "znBeYmRWw4MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 차원 축소"
      ],
      "metadata": {
        "id": "rnvc6vIPwyjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "ex = X.iloc[:, :2]\n",
        "only_X = X.iloc[:, 2:]\n",
        "pca = PCA(n_components=10)\n",
        "pca.fit(only_X)\n",
        "X_pca = pca.transform(only_X)\n",
        "print(X_pca.shape)\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n",
        "df = pd.DataFrame(X_pca, columns = ['comp1', 'comp2'])\n",
        "train = pd.concat([df, ex, y], axis=1)"
      ],
      "metadata": {
        "id": "wU3MqBX0yjfY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12327ec4-9c21-4e14-a119-e96584d26524"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(598, 10)\n",
            "[6.44050778e-01 3.55949222e-01 3.86317897e-15 4.50832735e-16\n",
            " 3.17290065e-18 1.61492020e-18 1.38025757e-18 4.02061723e-19\n",
            " 1.90043129e-19 4.73762644e-20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "ex = X.iloc[:, :2]\n",
        "only_X = X.iloc[:, 2:]\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(only_X,y)\n",
        "X_lda = lda.transform(only_X)\n",
        "\n",
        "\n",
        "ex_2 = test.iloc[:, :2]\n",
        "only_X_test = test.iloc[:, 2:]\n",
        "test_lda = lda.transform(only_X_test)\n",
        "test = pd.DataFrame(test_lda, columns = ['comp1', 'comp2'])\n",
        "test = pd.concat([test, ex_2], axis=1)\n",
        "\n",
        "\n",
        "df = pd.DataFrame(X_lda, columns = ['comp1', 'comp2'])\n",
        "train = pd.concat([df, ex, y], axis=1)\n",
        "X = train.drop('Y_Class', axis=1)\n",
        "y = train['Y_Class']"
      ],
      "metadata": {
        "id": "ZDxf81Lg0bTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. XGB"
      ],
      "metadata": {
        "id": "9NWbT0ZujlP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습함수 정의 \n",
        "def objective(trial: Trial, train):\n",
        "    param = {\n",
        "        'criterion' : 'absolute_error',\n",
        "        'tree_method' : 'exact',\n",
        "        'seed': 42, \n",
        "        'learning_rate' : trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'n_estimators':trial.suggest_int('n_estimators', 100, 1000),        \n",
        "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 9),\n",
        "        'max_depth' : trial.suggest_int('max_depth', 3, 30),\n",
        "        'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.2, 1.0),\n",
        "        'min_split_loss' : trial.suggest_loguniform('min_split_loss', 1e-3, 10.0),\n",
        "        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n",
        "        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n",
        "    }\n",
        "    cv_accuracy = []\n",
        "    cv = StratifiedKFold(n_splits = 5)\n",
        "    n_iter = 0\n",
        "\n",
        "    for t,v in cv.split(train, train['Y_Class']):\n",
        "        train_cv = train.iloc[t]\n",
        "        val_cv = train.iloc[v]\n",
        "\n",
        "        X = train_cv.drop('Y_Class', axis=1)\n",
        "        y = train_cv['Y_Class']\n",
        "\n",
        "        val_X = val_cv.drop('Y_Class', axis=1)\n",
        "        val_y = val_cv['Y_Class']\n",
        "\n",
        "        model = XGBClassifier(**param)\n",
        "\n",
        "        model.fit(X, y)\n",
        "        score = f1_score(val_y, model.predict(val_X), average = 'macro')\n",
        "\n",
        "        cv_accuracy.append(score)\n",
        "        n_iter += 1\n",
        "\n",
        "    return np.mean(cv_accuracy)\n",
        "\n",
        "\n",
        "# create study\n",
        "study = optuna.create_study(\n",
        "    direction='maximize',\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    pruner=optuna.pruners.HyperbandPruner(),\n",
        "    study_name='XGBClassifier-Hyperparameter-Tuning'\n",
        ")\n",
        "\n",
        "# 학습 \n",
        "study.optimize(lambda trial: objective(trial,train), \n",
        "               n_trials=50)\n",
        "print('Best trial : score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ],
      "metadata": {
        "id": "OI4oV31NhI4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. LGBM"
      ],
      "metadata": {
        "id": "yHnaCEjCjxD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습함수 정의 \n",
        "def objective(trial: Trial, train):\n",
        "\n",
        "    param = {\n",
        "        'verbose' : -1,\n",
        "        'random_state': 7, \n",
        "        'n_jobs': -1,\n",
        "        # 'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.7, 1.0),\n",
        "        # 'max_depth' : trial.suggest_int('max_depth', 2, 30),\n",
        "        # 'n_estimators' : trial.suggest_int('n_estimators', 500, 3000),\n",
        "        # 'learning_rate': trial.suggest_float('learning_rate', 0.1, 0.3), \n",
        "        'learning_rate' : 0.1,\n",
        "        # 'num_leaves' : trial.suggest_int('num_leaves', 5, 30),\n",
        "        # 'min_child_samples' : trial.suggest_int('min_child_samples', 2, 10),\n",
        "        # 'reg_alpha' : trial.suggest_float('reg_alpha', 1, 1.3),\n",
        "        # 'reg_lambda' : trial.suggest_float('reg_lambda', 1, 1.3)\n",
        "    }\n",
        "    cv_accuracy = []\n",
        "    cv = StratifiedKFold(n_splits = 5)\n",
        "    n_iter = 0\n",
        "\n",
        "    for t,v in cv.split(train, train['Y_Class']):\n",
        "        train_cv = train.iloc[t]\n",
        "        val_cv = train.iloc[v]\n",
        "\n",
        "        X = train_cv.drop('Y_Class', axis=1)\n",
        "        y = train_cv['Y_Class']\n",
        "\n",
        "        val_X = val_cv.drop('Y_Class', axis=1)\n",
        "        val_y = val_cv['Y_Class']\n",
        "\n",
        "        model = LGBMClassifier(**param)\n",
        "\n",
        "        model.fit(X, y)\n",
        "        score = f1_score(val_y, model.predict(val_X), average = 'macro')\n",
        "        print(score)\n",
        "\n",
        "        cv_accuracy.append(score)\n",
        "        n_iter += 1\n",
        "\n",
        "    return np.mean(cv_accuracy)\n",
        "\n",
        "# create study\n",
        "study = optuna.create_study(\n",
        "    direction='maximize',\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    pruner=optuna.pruners.HyperbandPruner(),\n",
        "    study_name='LGBM-Hyperparameter-Tuning'\n",
        ")\n",
        "\n",
        "# 학습 \n",
        "study.optimize(lambda trial: objective(trial,train),\n",
        "               n_trials=100)\n",
        "print('Best trial : score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ],
      "metadata": {
        "id": "nuVz1quQjj6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, stratify = y, random_state = 7)\n",
        "\n",
        "RF = RandomForestClassifier(random_state=7).fit(X_train, y_train)\n",
        "RF_pred = RF.predict(X_val)\n",
        "score = f1_score(y_val, RF_pred, average='macro')\n",
        "print(score)"
      ],
      "metadata": {
        "id": "K1_RYnputf9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LGBMClassifier(random_state=7).fit(X_train, y_train)\n",
        "pred = model.predict(X_val)\n",
        "score = f1_score(y_val, pred, average='macro')\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MBs-n3VuOFd",
        "outputId": "1fa615fa-eabe-45b9-ffb3-4cb8a14aab50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5929319467250501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier(random_state=7).fit(X_train, y_train)\n",
        "pred = model.predict(X_val)\n",
        "score = f1_score(y_val, pred, average='macro')\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQHkKEWmuh6q",
        "outputId": "45afc590-b92b-4c26-8942-461ff91d0cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5925925925925926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ExtraTreesClassifier(random_state=7).fit(X_train, y_train)\n",
        "pred = model.predict(X_val)\n",
        "score = f1_score(y_val, pred, average='macro')\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2funq1bCukIq",
        "outputId": "74861c81-d849-4a0f-e38e-d4e81e983d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6415491578535056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GradientBoostingClassifier(random_state=7).fit(X_train, y_train)\n",
        "pred = model.predict(X_val)\n",
        "score = f1_score(y_val, pred, average='macro')\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOvYFnmhy2Ak",
        "outputId": "644f7b5f-8596-414d-fd0e-0612eed1b03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6888888888888888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RF = RandomForestClassifier(random_state=43).fit(X, y)\n",
        "RF_pred = RF.predict(test)\n",
        "\n",
        "XGB = XGBClassifier(random_state=43).fit(X, y)\n",
        "XGB_pred = XGB.predict(test)\n",
        "\n",
        "LGBM = LGBMClassifier(random_state=43).fit(X, y)\n",
        "LGBM_pred = LGBM.predict(test)\n",
        "\n",
        "ET = ExtraTreesClassifier(random_state=43).fit(X, y)\n",
        "ET_pred = ET.predict(test)\n",
        "\n",
        "GB = GradientBoostingClassifier(random_state=43).fit(X, y)\n",
        "GB_pred = GB.predict(test)\n",
        "\n",
        "# 2랑 5가 멀쩡 "
      ],
      "metadata": {
        "id": "vFe8-nPPyeb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5개 다 쓰는 hard voting\n",
        "# https://wikidocs.net/42408\n",
        "\n",
        "def mode(list):\n",
        "    count = 0\n",
        "    mode = 0;\n",
        "    for x in list: \n",
        "        if list.count(x) > count:\n",
        "            count = list.count(x)\n",
        "            mode = x\n",
        "\n",
        "    return mode\n",
        "final_pred = []\n",
        "for i in range(0, len(RF_pred)):\n",
        "    final_pred.append(mode([RF_pred[i], XGB_pred[i], LGBM_pred[i], ET_pred[i], GB_pred[i]]))\n",
        "sample_submission['Y_Class'] = final_pred\n",
        "sample_submission['Y_Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHtTCwlS10ti",
        "outputId": "bfb65b75-0b5b-4fbd-c276-9d674aa26a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    268\n",
              "0     40\n",
              "2      2\n",
              "Name: Y_Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mode(list):\n",
        "    count = 0\n",
        "    mode = 0;\n",
        "    for x in list: \n",
        "        if list.count(x) > count:\n",
        "            count = list.count(x)\n",
        "            mode = x\n",
        "    return mode\n",
        "final_pred = []\n",
        "for i in range(0, len(RF_pred)):\n",
        "    final_pred.append(mode([GB_pred[i]]))\n",
        "sample_submission['Y_Class'] = final_pred\n",
        "sample_submission['Y_Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl8fQo5j2dhv",
        "outputId": "564ff0ca-4acb-4c7f-9f3c-fae24816f1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    242\n",
              "0     39\n",
              "2     29\n",
              "Name: Y_Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission.to_csv('./submit.csv', index=False)"
      ],
      "metadata": {
        "id": "B22ISQ7H2jj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ET"
      ],
      "metadata": {
        "id": "1A_5bF8soNF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습함수 정의 \n",
        "def objective(trial: Trial, train):\n",
        "    param = {\n",
        "        'verbose' : 1,\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1,\n",
        "        'max_depth' : trial.suggest_int('max_depth', 5, 50),\n",
        "        'ccp_alpha' : trial.suggest_float('ccp_alpha', 0, 0.3),\n",
        "        'n_estimators':trial.suggest_int('n_estimators', 500, 3000),\n",
        "        'min_impurity_decrease' : trial.suggest_float('min_impurity_decrease', 0, 0.5)\n",
        "    }\n",
        "    cv_accuracy = []\n",
        "    cv = StratifiedKFold(n_splits = 5)\n",
        "    n_iter = 0\n",
        "\n",
        "    for t,v in cv.split(train, train['Y_Class']):\n",
        "        train_cv = train.iloc[t]\n",
        "        val_cv = train.iloc[v]\n",
        "\n",
        "        X = train_cv.drop('Y_Class', axis=1)\n",
        "        y = train_cv['Y_Class']\n",
        "\n",
        "        val_X = val_cv.drop('Y_Class', axis=1)\n",
        "        val_y = val_cv['Y_Class']\n",
        "\n",
        "        model = ExtraTreesClassifier(**param)\n",
        "\n",
        "        model.fit(X, y)\n",
        "        score = f1_score(val_y, model.predict(val_X), average = 'macro')\n",
        "\n",
        "        cv_accuracy.append(score)\n",
        "        n_iter += 1\n",
        "\n",
        "    return np.mean(cv_accuracy)\n",
        "\n",
        "\n",
        "# create study\n",
        "study = optuna.create_study(\n",
        "    direction='maximize',\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    pruner=optuna.pruners.HyperbandPruner(),\n",
        "    study_name='ExtraTrees-Hyperparameter-Tuning'\n",
        ")\n",
        "\n",
        "# 학습 \n",
        "study.optimize(lambda trial: objective(trial,train), \n",
        "               n_trials=50)\n",
        "print('Best trial : score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ],
      "metadata": {
        "id": "y7YZq7Bbkc_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. GB"
      ],
      "metadata": {
        "id": "Os-HbRdq7gv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 7)\n",
        "\n",
        "# 학습함수 정의 \n",
        "def objective(trial: Trial, train):\n",
        "    param = {\n",
        "        'verbose' : 0,\n",
        "        'random_state': 7,\n",
        "        'n_iter_no_change' : 50,\n",
        "        'validation_fraction' : 0.1,\n",
        "        'learning_rate' : 0.1,\n",
        "        'n_estimators' : trial.suggest_int('n_estimators', 100, 2000, step=20),\n",
        "        'min_impurity_decrease' : trial.suggest_float('min_impurity_decrease', 0, 0.2),\n",
        "        'max_depth' : trial.suggest_int('max_depth', 2, 20),\n",
        "        'max_features' : trial.suggest_categorical('max_features', ['auto', 'log2']),\n",
        "        'subsample' : trial.suggest_float('subsample', 0.7, 1.0, step=0.1)\n",
        "    }\n",
        "    cv_accuracy = []\n",
        "    cv = KFold(n_splits = 5)\n",
        "    n_iter = 0\n",
        "\n",
        "    for t,v in cv.split(train, train['Y_Quality']):\n",
        "        train_cv = train.iloc[t]\n",
        "        val_cv = train.iloc[v]\n",
        "\n",
        "        X = train_cv.drop('Y_Quality', axis=1)\n",
        "        y = train_cv['Y_Quality']\n",
        "\n",
        "        val_X = val_cv.drop('Y_Quality', axis=1)\n",
        "        val_y = val_cv['Y_Quality']\n",
        "\n",
        "        model = GradientBoostingRegressor(**param)\n",
        "\n",
        "        model.fit(X, y)\n",
        "        score = mean_squared_error(val_y, model.predict(val_X), squared = False)\n",
        "\n",
        "        cv_accuracy.append(score)\n",
        "        n_iter += 1\n",
        "\n",
        "    return np.mean(cv_accuracy)\n",
        "\n",
        "    # model = GradientBoostingRegressor(**param)\n",
        "    # model.fit(X_train, y_train)\n",
        "    # score = f1_score(y_val, model.predict(X_val), average='macro')\n",
        "\n",
        "    # return score\n",
        "\n",
        "# create study\n",
        "study = optuna.create_study(\n",
        "    direction='maximize',\n",
        "    sampler=optuna.samplers.TPESampler(seed=42),\n",
        "    pruner=optuna.pruners.HyperbandPruner(),\n",
        "    study_name='GB-Hyperparameter-Tuning'\n",
        ")\n",
        "\n",
        "# 학습 \n",
        "study.optimize(lambda trial: objective(trial,train), \n",
        "               n_trials=50)\n",
        "print('Best trial : score {}, \\nparams {}'.format(study.best_trial.value, study.best_trial.params))"
      ],
      "metadata": {
        "id": "oay2Gzkp7ht2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "a985600a-3310-4094-d97c-dc8b282a1a4c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         LINE  PRODUCT_CODE   X_1       X_2  X_4  X_5   X_7  X_8       X_9  \\\n",
              "0   -0.666667          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "1   -0.333333          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "2   -0.666667          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "3   -0.333333          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "4   -0.666667          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "..        ...           ...   ...       ...  ...  ...   ...  ...       ...   \n",
              "593  0.333333           0.0   0.0  0.042105  0.0  0.0  0.10  0.0  0.403846   \n",
              "594 -0.666667          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "595 -0.666667          -1.0  -1.0 -0.957895 -1.0 -1.0 -0.90 -1.0 -0.596154   \n",
              "596  0.000000          -0.5  19.0  0.031579  0.0  0.1  0.00  0.0  0.000000   \n",
              "597  0.333333          -0.5   9.5 -0.042105  0.0  0.0  0.32  0.0  0.403846   \n",
              "\n",
              "     X_10  ...    X_2864    X_2865  X_2866  X_2867  X_2868  X_2869  X_2870  \\\n",
              "0    -1.0  ...  0.997188  1.000000   39.34   40.89   32.56   34.09   77.77   \n",
              "1    -1.0  ...  0.995670  1.000000   38.89   42.82   43.92   35.34   72.55   \n",
              "2    -1.0  ...  0.994547  1.000000   39.19   36.65   42.47   36.53   78.35   \n",
              "3    -1.0  ...  0.999604  1.000000   37.74   39.17   52.17   30.58   71.78   \n",
              "4    -1.0  ...  0.994631  0.997167   38.70   41.89   46.93   33.09   76.97   \n",
              "..    ...  ...       ...       ...     ...     ...     ...     ...     ...   \n",
              "593   0.0  ...  0.000000  0.000000    0.00    0.00    0.00    0.00    0.00   \n",
              "594  -1.0  ...  1.001290  1.000000   49.47   53.07   50.89   55.10   66.49   \n",
              "595  -1.0  ...  0.993729  0.997167    0.00    0.00    0.00    0.00    0.00   \n",
              "596   0.0  ...  0.000000  0.000000    0.00    0.00    0.00    0.00    0.00   \n",
              "597   0.0  ...  0.000000  0.000000    0.00    0.00    0.00    0.00    0.00   \n",
              "\n",
              "     X_2871  Y_Class  Y_Quality  \n",
              "0       0.0        1   0.533433  \n",
              "1       0.0        2   0.541819  \n",
              "2       0.0        1   0.531267  \n",
              "3       0.0        2   0.537325  \n",
              "4       0.0        1   0.531590  \n",
              "..      ...      ...        ...  \n",
              "593     0.0        1   0.526546  \n",
              "594     1.0        0   0.524022  \n",
              "595     1.0        0   0.521289  \n",
              "596     0.0        1   0.531375  \n",
              "597     0.0        1   0.533702  \n",
              "\n",
              "[598 rows x 2598 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df4aba2e-29ce-423a-ac61-d804a2326a99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LINE</th>\n",
              "      <th>PRODUCT_CODE</th>\n",
              "      <th>X_1</th>\n",
              "      <th>X_2</th>\n",
              "      <th>X_4</th>\n",
              "      <th>X_5</th>\n",
              "      <th>X_7</th>\n",
              "      <th>X_8</th>\n",
              "      <th>X_9</th>\n",
              "      <th>X_10</th>\n",
              "      <th>...</th>\n",
              "      <th>X_2864</th>\n",
              "      <th>X_2865</th>\n",
              "      <th>X_2866</th>\n",
              "      <th>X_2867</th>\n",
              "      <th>X_2868</th>\n",
              "      <th>X_2869</th>\n",
              "      <th>X_2870</th>\n",
              "      <th>X_2871</th>\n",
              "      <th>Y_Class</th>\n",
              "      <th>Y_Quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.997188</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>39.34</td>\n",
              "      <td>40.89</td>\n",
              "      <td>32.56</td>\n",
              "      <td>34.09</td>\n",
              "      <td>77.77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.533433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.995670</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>38.89</td>\n",
              "      <td>42.82</td>\n",
              "      <td>43.92</td>\n",
              "      <td>35.34</td>\n",
              "      <td>72.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.541819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.994547</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>39.19</td>\n",
              "      <td>36.65</td>\n",
              "      <td>42.47</td>\n",
              "      <td>36.53</td>\n",
              "      <td>78.35</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.531267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.999604</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>37.74</td>\n",
              "      <td>39.17</td>\n",
              "      <td>52.17</td>\n",
              "      <td>30.58</td>\n",
              "      <td>71.78</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.537325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.994631</td>\n",
              "      <td>0.997167</td>\n",
              "      <td>38.70</td>\n",
              "      <td>41.89</td>\n",
              "      <td>46.93</td>\n",
              "      <td>33.09</td>\n",
              "      <td>76.97</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.531590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>593</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042105</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.403846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.526546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.001290</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>49.47</td>\n",
              "      <td>53.07</td>\n",
              "      <td>50.89</td>\n",
              "      <td>55.10</td>\n",
              "      <td>66.49</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.524022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.957895</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.596154</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.993729</td>\n",
              "      <td>0.997167</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.521289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.031579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.531375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>9.5</td>\n",
              "      <td>-0.042105</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.403846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.533702</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>598 rows × 2598 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df4aba2e-29ce-423a-ac61-d804a2326a99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df4aba2e-29ce-423a-ac61-d804a2326a99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df4aba2e-29ce-423a-ac61-d804a2326a99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GB_model = GradientBoostingClassifier(random_state = 42, n_iter_no_change = 50, validation_fraction = 0.1, n_estimators = 1900, \n",
        "                                      learning_rate = 0.05, min_impurity_decrease = 0.07031308605404483, max_depth = 2)\n",
        "GB_model.fit(X, y)\n",
        "GB_pred = GB_model.predict(test)\n",
        "pd.DataFrame(GB_pred).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofq2_xYiB3w5",
        "outputId": "825b20e7-7449-4cfe-9d85-0d1cd59406be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    242\n",
              "2     39\n",
              "0     29\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GB_model = GradientBoostingClassifier(**study.best_trial.params, random_state = 42, n_iter_no_change = 50, validation_fraction = 0.1, learning_rate = 0.05)\n",
        "GB_model.fit(X, y)\n",
        "GB_pred = GB_model.predict(test)\n",
        "print(pd.DataFrame(GB_pred).value_counts())\n",
        "\n",
        "sample_submission['Y_Class'] = GB_pred\n",
        "sample_submission.to_csv('./submit.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxv63HuIY2lh",
        "outputId": "e3296ad1-4054-4f70-8eb4-f068d89ce95d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    241\n",
            "2     39\n",
            "0     30\n",
            "dtype: int64\n"
          ]
        }
      ]
    }
  ]
}